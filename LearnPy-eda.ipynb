{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Suplementary-Material-for-Exloratory-Data-Analysis\" data-toc-modified-id=\"Suplementary-Material-for-Exloratory-Data-Analysis-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Suplementary Material for Exloratory Data Analysis</a></span></li><li><span><a href=\"#Case-#1:-Finding-the-right-phone\" data-toc-modified-id=\"Case-#1:-Finding-the-right-phone-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Case #1: Finding the right phone</a></span></li><li><span><a href=\"#Case-#2:-A-treat-for-Loyal-Customer\" data-toc-modified-id=\"Case-#2:-A-treat-for-Loyal-Customer-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Case #2: A treat for Loyal Customer</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suplementary Material for Exloratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case #1: Finding the right phone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say, by a chance, you're asked to make a You*ube video content about \"The Phone of 2019\". You currently have no clue about what the best phone whatsoever. Luckily, your friend gave you a scraped data from your local's online retail.\n",
    "Read the data using :\n",
    "```python \n",
    "pd.read_csv('data_input/handphone.csv', encoding='ISO-8859-1')\n",
    "```\n",
    "Don't worry about the encoding things, it's just a matter on how the text is represented using standad codes (usually `utf-8`)\n",
    "\n",
    "Use the data to answer these following questions in order to help you take a glance on the data:\n",
    "\n",
    "1. Find the top 5% of the most reviewed phone. \n",
    "\n",
    "2. Get 3 most frequent brand based on answer no.1 <br>\n",
    "What brand doesn't belong to the top 3 ? \n",
    "- [ ] Xiaomi\n",
    "- [ ] Oppo\n",
    "- [ ] Apple\n",
    "- [ ] Vivo\n",
    "\n",
    "\n",
    "3. Based on answer no.2, compare the average price for each brand. What brand has the highest average price ? \n",
    "- [ ] Xiaomi\n",
    "- [ ] Oppo\n",
    "- [ ] Apple\n",
    "- [ ] Vivo\n",
    "\n",
    "\n",
    "4. Based on answer no.2, what brand vary the most on its price ? \n",
    "- [ ] Xiaomi\n",
    "- [ ] Oppo\n",
    "- [ ] Apple\n",
    "- [ ] Vivo\n",
    "\n",
    "If you have answered all the questions above, you may conclude what brand you are going to nominate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Answer no 1</summary>\n",
    "    \n",
    "In order to get the top 5%, you can sort the data descending based on its review using `sort_values`. Then, take the first 5% row according to the data length using `round(len(data)*0.05)`. \n",
    "```python \n",
    "    data = data.sort_values(by='review', ascending=False)\n",
    "    five_percent = round(len(data)*0.05)\n",
    "    top_five_percent = data.head(five_percent)\n",
    "```\n",
    "<br>\n",
    "    \n",
    "Alternatively, pandas gives us the `.quantile` method to get the n-th% value. In order to get all top 5% data, we need to select all the data that pass the 95% value using `data[review].quantile(0.95)`. See the following codes \n",
    "```python \n",
    "    threshold = data['review'].quantile(0.95)\n",
    "    condition = data['review'] >= threshold\n",
    "    top_five_percent = data[condition]\n",
    "```\n",
    "<br>\n",
    "    \n",
    "</details>\n",
    "\n",
    "<details><summary>Answer no 2</summary>\n",
    "    \n",
    "You can use `value_counts()` method in order to automatically sort value frequencies from highest to lowest. You can then take top 3 using `head` and get the index values\n",
    "    \n",
    "```python\n",
    "    data['brand_hp'].value_counts().head(3).index.values\n",
    "```\n",
    "    \n",
    "</details>\n",
    "\n",
    "<details><summary>Answer no 3</summary>\n",
    "\n",
    "In order to answer question no 3 and 4, you need to specifically inspect each brand manually (Don't worry, you can use groupby later)\n",
    "\n",
    "```python\n",
    "    condition1 = data['brand_hp'] == 'specific brand1'\n",
    "    condition2 = data['brand_hp'] == 'specific brand2'\n",
    "    condition3 = data['brand_hp'] == 'specific brand3'\n",
    "    data_brand1 = data[condition1]\n",
    "    data_brand2 = data[condition2]\n",
    "    data_brand3 = data[condition3]\n",
    "    \n",
    "    print(data_brand1['price'].mean())\n",
    "    print(data_brand2['price'].mean())\n",
    "    print(data_brand3['price'].mean())\n",
    "```\n",
    "<br>\n",
    "    \n",
    "</details>\n",
    "\n",
    "<details><summary>Answer no 4</summary>\n",
    "\n",
    "Similar to no.3, but instead of mean, we change the function to std (Standard Deviation) to measure how much big the variation of the values. \n",
    "    \n",
    "```python\n",
    "    condition1 = data['brand_hp'] == 'specific brand1'\n",
    "    condition1 = data['brand_hp'] == 'specific brand2'\n",
    "    condition1 = data['brand_hp'] == 'specific brand3'\n",
    "    data_brand1 = data[condition1]\n",
    "    data_brand2 = data[condition2]\n",
    "    data_brand3 = data[condition3]\n",
    "    \n",
    "    print(data_brand1['price'].std())\n",
    "    print(data_brand2['price'].std())\n",
    "    print(data_brand3['price'].std())\n",
    "```\n",
    "  \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case #2: A treat for Loyal Customer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are now act as owner of the multi-nation store mainly located in UK, and currently looking for a branch in France. In order to grow the France market, you wanted to give a treat for loyal customer in France beforehand. Who will be rewarded and How's France market compared to other nations ? \n",
    "\n",
    "Go take the data using \n",
    "```python \n",
    "pd.read_csv('data_input/online-retail.csv', encoding='ISO-8859-1', parse_dates=['InvoiceDate'])\n",
    "```\n",
    "and select only `France` country. Answer these questions in order to do execute your plan: \n",
    "\n",
    "1. Get the top 10 most frequent customer\n",
    "2. In what month do they frequently do the transactions? (Get the top3 month). What month doesn't belong to the top 3 ? \n",
    "- [ ] September \n",
    "- [ ] October\n",
    "- [ ] November\n",
    "- [ ] December\n",
    "\n",
    "3. What are 10 items do they frequently buy in the top3 most frequent month (ignoring the `quantity`) ? Select item that doesn't belong to those top 10\n",
    "- [ ] WHITE HANGING HEART T-LIGHT HOLDER\n",
    "- [ ] LUNCH BOX WITH CUTLERY RETROSPOT\n",
    "- [ ] PLASTERS IN TIN CIRCUS PARADE\n",
    "- [ ] RABBIT NIGHT LIGHT\n",
    "\n",
    "4. Compare the revenue of those 10 items between France (use France data) and all over the country (use all the data) in order to see the proportion of France market compared to all the market. What is the proportion of France market? ?. <br>\n",
    "*notes: you can calculate revenue by multiplying unit price with the quantity of each transactions*\n",
    "- [ ] 13.03 %\n",
    "- [ ] 13.08 %\n",
    "- [ ] 0.3 %\n",
    "- [ ] 20.6 %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you already find the answer, you might have to discount the item on the most active month in the future, and gives rewards for those ten customer in France. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you find any problem, don't hesitate to take a look at these reference answer. (Your answer doesn't have to be exactly the same)\n",
    "<details><summary>Answer no.1</summary>\n",
    "\n",
    "The only customer attribute(s) existed in the data is `CustomerID`. So let's find the most frequent `CustomerID` (Assuming we don't care about Quantity values). \n",
    "\n",
    "First we need to select only france data. After that, we can simply count values the `CustomerID` and take `.head(10)` the get the top 10 most frequent customer. Don't forget to obtain the customer id using `.index.values` after `.value_counts()`:\n",
    "```python\n",
    "    france = data[data['Country'] == 'France']\n",
    "    top10_user = france['CustomerID'].value_counts().head(10).index.values\n",
    "    top10_user\n",
    "```\n",
    "<br>\n",
    "</details>\n",
    "\n",
    "\n",
    "<details><summary>Answer no.2</summary>\n",
    "\n",
    "To answer such question, we need to narrow down our data focusing only on those top 10 customer. Using `.isin()` method, you can filter the customers. <br>\n",
    "After you filter it out, extract the month name using `.dt.month_name()` from `InvoiceDate` columns and count the values using `value_counts()`:\n",
    "\n",
    "```python\n",
    "condition = france['CustomerID'].isin(top10_user)\n",
    "data_customer = france[condition]\n",
    "data_customer['Month'] = data_customer['InvoiceDate'].dt.month_name()\n",
    "top3_month = data_customer['Month'].value_counts().head(3).index.values\n",
    "top3_month\n",
    "```\n",
    "    \n",
    "</details>\n",
    "\n",
    "<details><summary>Answer no. 3</summary>\n",
    "    \n",
    "You need to get the top 3 most frequent month first. Using `.count_values()` you can select top 3 month from `Month` columns. Get the month names, and filter out only data that consist on of those names.<br>\n",
    "Finally, do some value_counts() based on `StockCode` to findout product's category. <br>\n",
    "In order to get the descriptions, filter the dataframe's `StockCode` using `.isin`. But, since `.isin` return all the data, we need to drop_duplciate so that we only show 10 products descriptions respectively <br><br>\n",
    "    \n",
    "```python\n",
    "top3_month = data_customer['Month'].value_counts().head(3).index.values\n",
    "condition = data_customer['Month'].isin(top3_month)\n",
    "data_month = data_customer[condition]\n",
    "stock_code = data_month['StockCode'].value_counts().head(10).index.values\n",
    "unique_item = data_month[data_month['StockCode'].isin(stock_code)].drop_duplicates(subset=['StockCode'])\n",
    "top10_unique = unique_item['Description'].unique()\n",
    "```\n",
    "<br>\n",
    "<br>\n",
    "</details>\n",
    "\n",
    "<details><summary>Answer no. 4</summary>\n",
    "\n",
    "To answer this questions, we have to measure the revenue for all the data. Hence, let's start over from reading the data, then add new column called `Revenue` wich the value is the product of `data['Quantity']` and `data['UnitPrice']`. <br>\n",
    "After `Revenue` column is created, subset the the France-only data, then calculate the sum of `Revenue` for both France-only data and the data. Compare both values and we will have the result. \n",
    "    \n",
    "```python\n",
    "data = pd.read_csv('data_input/online-retail.csv', encoding='ISO-8859-1', parse_dates=['InvoiceDate'])\n",
    "condition_france = data['Country'] == 'France'\n",
    "condition_item = data['Description'].isin(top10_unique)\n",
    "data['Revenue'] = data['Quantity'] * data['UnitPrice']\n",
    "\n",
    "france = data[condition_france&condition_item]\n",
    "proportion = france.groupby('Description').sum()['Revenue'].sum()/data[condition_item].groupby('Description').sum()['Revenue'].sum()\n",
    "\n",
    "print('France Proportion: ', round(proportion*100, 2), '%')\n",
    "```\n",
    "    \n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qoppa-new",
   "language": "python",
   "name": "qoppa-new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
